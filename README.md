# План разработки микросервесного приложения WikiSearch
## MVP
### Парсинг википедии
1. Начинаем со стартовой
2. Достаем относительные ссылки регуляркой `<a href="(\/[^#"]+)"`
3. Достаем дату изменения страницы
4. Отправляем в графопостроитель
### Построение графа из ссылок
1. Все ссылки, найденные на текущей странице, добавляются в граф
2. Граф должен сохраняться в БД
### Поиск пути от страницы к странице
1. Проработать вариант построения маршрута через рекурсивный запрос к БД
2. Запасной вариант - А*, в этом случае нужно будет подгружать из БД смежные узлы графа
# Проблемы текущей реализации
1. Никак не масштабируется
2. Никак не унифицируется
## Деление на микросервисы и докеризация
### Спроектировать архитектуру
1. Нарисовать диаграмму компонентов
2. Написать контракты сервисов-компонентов
### Реализация
1. Реализовать сервисы, наполнив логикой из предыдущего этапа: ходилки
2. Реализовать обнаружение сервисами друг друга (Service Discovery) - Consul, Eureka и т.д.
3. Написать докерфайл к каждому сервису
4. Написать докер-компоуз файл для всей системы
5. Отладить запуск с нуля и написать инструкцию по деплою и эксплуатации
6. Ходилки теперь вызывают отдельный микросервис Графопостроитель
## Внедрение шины данных
### Kafka: установка, настройка, добавление в compose 
1. Конфигурирование стартовых настроек по умолчанию
2. Создание двух шин данных: очередь входящих ссылок для ходилок и очередь исходящих (вытащенных) "сырых" (неуникальных) ссылок для унификаторов
3. Интеграция ходилок с шиной входящих ссылок - должны брать данные оттуда
4. Интеграция ходилок с шиной сырых ссылок: все найденные класть туда
### Микросервис Унификатор
1. Контракт
2. Интеграция с двумя шинами: берет из "сырой" очереди, уникальные кладет в шину для ходилок
3. Интеграция с БД графа и бизнес-логика унификации
4. Гарантия уникальности с помощью Кафки (запасной план - таблица "in progress" в БД)
